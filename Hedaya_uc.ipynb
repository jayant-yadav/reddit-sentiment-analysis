{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83eaad4d-bbb4-4ec5-8412-206eed358489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/ubuntu/spark-3.2.1-bin-hadoop3.2/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/ubuntu/.ivy2/cache\n",
      "The jars for the packages stored in: /home/ubuntu/.ivy2/jars\n",
      "org.mongodb.spark#mongo-spark-connector_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-03940523-7c8b-4bd9-b7cc-29acdbe26558;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.mongodb.spark#mongo-spark-connector_2.12;3.0.1 in central\n",
      "\tfound org.mongodb#mongodb-driver-sync;4.0.5 in central\n",
      "\tfound org.mongodb#bson;4.0.5 in central\n",
      "\tfound org.mongodb#mongodb-driver-core;4.0.5 in central\n",
      ":: resolution report :: resolve 935ms :: artifacts dl 17ms\n",
      "\t:: modules in use:\n",
      "\torg.mongodb#bson;4.0.5 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-core;4.0.5 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-sync;4.0.5 from central in [default]\n",
      "\torg.mongodb.spark#mongo-spark-connector_2.12;3.0.1 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   4   |   0   |   0   |   0   ||   4   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-03940523-7c8b-4bd9-b7cc-29acdbe26558\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 4 already retrieved (0kB/12ms)\n",
      "22/03/18 16:57:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/03/18 16:57:58 WARN ExecutorAllocationManager: Dynamic allocation without a shuffle service is an experimental feature.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import time\n",
    "# packacges that needs to be installed across all nodes:\n",
    "from textblob import TextBlob \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from collections import Counter\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "# New API\n",
    "spark_session = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"spark://192.168.2.197:7077\") \\\n",
    "        .appName(\"Hedaya_uc\")\\\n",
    "        .config(\"spark.executor.cores\",2)\\\n",
    "        .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "        .config(\"spark.dynamicAllocation.shuffleTracking.enabled\", True)\\\n",
    "        .config(\"spark.shuffle.service.enabled\", False)\\\n",
    "        .config(\"spark.dynamicAllocation.executorIdleTimeout\",\"60s\")\\\n",
    "        .config(\"spark.driver.port\",9998)\\\n",
    "        .config(\"spark.blockManager.port\",10005)\\\n",
    "        .config(\"spark.mongodb.input.uri\", \"mongodb://127.0.0.1/Reddit.comments\") \\\n",
    "        .config(\"spark.mongodb.output.uri\", \"mongodb://127.0.0.1/Reddit.comments\") \\\n",
    "        .config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.1\")\\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Old API (RDD)\n",
    "spark_context = spark_session.sparkContext\n",
    "\n",
    "spark_context.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cc2b5f7-dc58-46fb-8f2e-dff5794d960f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#starts timing\n",
    "start_time = time.time()\n",
    "#path to the file\n",
    "path = 'hdfs://130.238.28.151:9000/user/hadoop/RC_2010-01'\n",
    "#reading the json file as a dataframe\n",
    "df = spark_session.read\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .json(path)\\\n",
    "    .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "487fcad4-dd87-4bfc-8452-ddfbee641c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95982c4d-5b95-40b4-aff0-c42b35b7abb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "518a8540-b50a-4482-8995-d2d1d720a764",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_subreddit_score = df.groupBy(\"subreddit\").agg({'score': 'avg'})\n",
    "\n",
    "avg_subreddit_score_sorted = avg_subreddit_score.orderBy('avg(score)',ascending = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6498761e-2f4b-42dd-9aa2-d2995d9bd75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 20 kindest subreddits based on average comment score are:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/18 17:04:00 ERROR TaskSchedulerImpl: Lost executor 2 on 192.168.2.197: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "[Stage 1:========================================================(15 + -2) / 13]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------+\n",
      "|     subreddit|        avg(score)|\n",
      "+--------------+------------------+\n",
      "|    bestof2009|41.943885653785074|\n",
      "|        tattoo|              20.0|\n",
      "|          digg|              13.0|\n",
      "|doesanyoneelse| 9.666666666666666|\n",
      "| announcements| 8.293814432989691|\n",
      "|         latin|7.7272727272727275|\n",
      "|      Nautical|              7.25|\n",
      "|         Forts|               7.0|\n",
      "|          blog| 6.954072398190045|\n",
      "|     Lovecraft| 6.333333333333333|\n",
      "|         funny| 6.329083665338645|\n",
      "|          xkcd|             6.158|\n",
      "|         Bacon| 6.102348993288591|\n",
      "|     malkovich|               6.0|\n",
      "|    homeopathy|               6.0|\n",
      "|         Eesti|               6.0|\n",
      "| worldbuilding| 5.888888888888889|\n",
      "|        bestof| 5.669226225634968|\n",
      "|  ChatRoulette|               5.5|\n",
      "|           WTF| 5.459002403427497|\n",
      "+--------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:========================================================(15 + -2) / 13]\r"
     ]
    }
   ],
   "source": [
    "print(\"The top 20 kindest subreddits based on average comment score are:\")\n",
    "avg_subreddit_score_sorted.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5ff6029-324d-492c-8250-4660f6c410be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 101.16121912002563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:========================================================(15 + -2) / 13]\r"
     ]
    }
   ],
   "source": [
    "print(f\"Execution time: {time.time() - start_time}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
