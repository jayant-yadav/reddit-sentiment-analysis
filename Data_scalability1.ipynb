{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9a89af7-11de-4ea7-a1a0-0ff244e97626",
   "metadata": {},
   "source": [
    "## Data size = 1.58 GB (RC_2010-01), Node = 4 (1 master + 3 workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b42d13aa-a23b-4972-a75a-4a878f3b0b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import time\n",
    "# packacges that needs to be installed across all nodes:\n",
    "from textblob import TextBlob \n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "929c1258-4ea9-488e-a23e-11c7c86dae2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/03/18 22:58:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/03/18 22:58:03 WARN ExecutorAllocationManager: Dynamic allocation without a shuffle service is an experimental feature.\n"
     ]
    }
   ],
   "source": [
    "spark_session = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"spark://192.168.2.197:7077\") \\\n",
    "        .appName(\"project_code_uc\")\\\n",
    "        .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "        .config(\"spark.dynamicAllocation.shuffleTracking.enabled\",True)\\\n",
    "        .config(\"spark.shuffle.service.enabled\", False)\\\n",
    "        .config(\"spark.dynamicAllocation.executorIdleTimeout\",\"30s\")\\\n",
    "        .config(\"spark.executor.cores\",2)\\\n",
    "        .config(\"spark.driver.port\",9998)\\\n",
    "        .config(\"spark.blockManager.port\",10005)\\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Old API (RDD)\n",
    "spark_context = spark_session.sparkContext\n",
    "\n",
    "spark_context.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3056ff9d-7cbe-4aa0-adca-0e7fce26a8a2",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1424411-dd56-4069-9fdc-e8ab35e477ce",
   "metadata": {},
   "source": [
    "### Start time count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b950093f-39b9-435b-96f1-4ad6b3cd4b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e9d0b95-68f4-45a5-8de4-87fe9086bb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data_frame = spark_session.read\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .json('hdfs://192.168.2.197:9000/user/hadoop/RC_2010-01')\\\n",
    "    .cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150b68ce-9c20-44c5-be5c-72612cf1d0b4",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285833fd-7a0d-48f1-9736-7c58f0cb1bc7",
   "metadata": {},
   "source": [
    "## Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d55917f7-c9d9-4cd6-8fbb-cc82c3bf0ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Cleaning text before analysis\n",
    "\n",
    "rcb_df = data_frame.select('body')\n",
    "rcb_df = rcb_df.dropna()\n",
    "rcb_df = rcb_df.filter(rcb_df['body'] != '[deleted]')\n",
    "\n",
    "#removing stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = stopwords.words(\"english\")\n",
    "\n",
    "def remove_stopwords_fnc(x):        \n",
    "    text = ''\n",
    "    for x in x.split(' '):\n",
    "        if x.lower() not in stop_words:\n",
    "            text += x + ' '\n",
    "        else:\n",
    "            pass\n",
    "    return text\n",
    "\n",
    "remove_stopwords_udf = udf(remove_stopwords_fnc)\n",
    "spark_session.udf.register(\"remove_stopwords_udf\", remove_stopwords_udf)\n",
    "rcb_df = rcb_df.withColumn('body',remove_stopwords_udf('body'))\n",
    "\n",
    "# rcb_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec0c575c-dc13-4ef6-886d-ca04c7b4d167",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                body|     sentiment_score|\n",
      "+--------------------+--------------------+\n",
      "|Good rant, stop l...| 0.11613636363636362|\n",
      "|    Sounds good me. |                 0.7|\n",
      "|Ok people donate ...| 0.04999999999999999|\n",
      "|               red? |                 0.0|\n",
      "|really want give ...| 0.02938311688311688|\n",
      "|school, depends p...| 0.13333333333333333|\n",
      "|they?  know recen...| 0.16666666666666666|\n",
      "|I'll add voice. b...|                -0.5|\n",
      "|        worry 2012. |                 0.0|\n",
      "|[George Carlin sa...|              0.1875|\n",
      "|No, like that. He...|                 0.0|\n",
      "|sad her.  been. k...|-0.28214285714285714|\n",
      "|realize 'assclown...|                -0.1|\n",
      "|sure wants back. ...| 0.06643518518518518|\n",
      "|cat consider dog ...|                 0.0|\n",
      "|hate uninformed r...|-0.05510204081632656|\n",
      "|No, found sack po...|               -0.75|\n",
      "|Feds take fall fi...|0.024999999999999994|\n",
      "|   to, omgomgomgomg |                 0.0|\n",
      "|moved quite bit a...| 0.11666666666666665|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def sentiment_fnc(text):\n",
    "    return TextBlob(text).sentiment.polarity #gives the polarity of the sentiment, [-1.0, 1.0]\n",
    "    \n",
    "\n",
    "sentiment_udf = udf(lambda x: sentiment_fnc(x)) \n",
    "spark_session.udf.register(\"sentiment_udf\", sentiment_udf)\n",
    "rcb_df = rcb_df.withColumn('sentiment_score',sentiment_udf('body').cast('double'))\n",
    "\n",
    "rcb_df.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b940d368-0a4b-4c3f-9d46-6a1aee212246",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e927c9b5-dfbb-46c2-bb31-8e51486ed441",
   "metadata": {},
   "source": [
    "## The discussion topics on a subreddit using keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34ba4abc-dd99-4447-9f51-4087ea7761a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 20 kindest subreddits based on average comment score are:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:====================================================>    (12 + 1) / 13]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------+\n",
      "|     subreddit|        avg(score)|\n",
      "+--------------+------------------+\n",
      "|    bestof2009|41.943885653785074|\n",
      "|        tattoo|              20.0|\n",
      "|          digg|              13.0|\n",
      "|doesanyoneelse| 9.666666666666666|\n",
      "| announcements| 8.293814432989691|\n",
      "|         latin|7.7272727272727275|\n",
      "|      Nautical|              7.25|\n",
      "|         Forts|               7.0|\n",
      "|          blog| 6.954072398190045|\n",
      "|     Lovecraft| 6.333333333333333|\n",
      "|         funny| 6.329083665338645|\n",
      "|          xkcd|             6.158|\n",
      "|         Bacon| 6.102348993288591|\n",
      "|         Eesti|               6.0|\n",
      "|     malkovich|               6.0|\n",
      "|    homeopathy|               6.0|\n",
      "| worldbuilding| 5.888888888888889|\n",
      "|        bestof| 5.669226225634968|\n",
      "|  ChatRoulette|               5.5|\n",
      "|           WTF| 5.459002403427497|\n",
      "+--------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "avg_subreddit_score = data_frame.groupBy(\"subreddit\").agg({'score': 'avg'})\n",
    "avg_subreddit_score_sorted = avg_subreddit_score.orderBy('avg(score)',ascending = False)\n",
    "print(\"The top 20 kindest subreddits based on average comment score are:\")\n",
    "avg_subreddit_score_sorted.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c6b37e-189a-4ca8-9d34-cbfd9015d33e",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e25666d-7d7e-4c4c-a0ac-ffe090b35d30",
   "metadata": {},
   "source": [
    "## What are the most active subreddits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3463637-a105-4171-a3bf-115dd55c59ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subreddit = data_frame.select('subreddit')\n",
    "df_subreddit = df_subreddit.dropna()\n",
    "df_subreddit_frequency = df_subreddit.groupby(\"subreddit\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "464d13cd-558b-4f3b-ae4c-8bac4f0ecb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:===========================================>             (10 + 3) / 13]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+\n",
      "|          subreddit| count|\n",
      "+-------------------+------+\n",
      "|          AskReddit|623825|\n",
      "|         reddit.com|300476|\n",
      "|               pics|198009|\n",
      "|           politics|146922|\n",
      "|               IAmA|135360|\n",
      "|                WTF|114836|\n",
      "|             gaming|113877|\n",
      "|              funny| 80320|\n",
      "|            atheism| 71549|\n",
      "|            science| 70028|\n",
      "|        programming| 66474|\n",
      "|          worldnews| 65451|\n",
      "|         technology| 49710|\n",
      "|    DoesAnybodyElse| 37237|\n",
      "|              Music| 26250|\n",
      "|relationship_advice| 23163|\n",
      "|fffffffuuuuuuuuuuuu| 20700|\n",
      "|          Economics| 19635|\n",
      "|             videos| 18558|\n",
      "|              trees| 18314|\n",
      "+-------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_subreddit_f = df_subreddit_frequency.sort('count',ascending=False).show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb45b7a9-1e5e-4b4c-a7ea-00d725e5a30a",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cb2df8-a557-4853-b3c1-3b390538f6dd",
   "metadata": {},
   "source": [
    "### Execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f47d47ba-909a-4f82-b9e3-9acee888e2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 55.943530321121216\n"
     ]
    }
   ],
   "source": [
    "print(f\"Execution time: {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f042798-0428-4cc8-8e91-371f70e8339a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
