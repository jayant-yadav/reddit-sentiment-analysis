{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13430beb-4259-4955-b3c2-c97b27ed12d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/03/15 18:30:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/03/15 18:30:47 WARN ExecutorAllocationManager: Dynamic allocation without a shuffle service is an experimental feature.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import json\n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "# New API\n",
    "spark_session = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"spark://192.168.2.197:7077\") \\\n",
    "        .appName(\"Test_ReddiComments\")\\\n",
    "        .config(\"spark.executor.cores\",2)\\\n",
    "        .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "        .config(\"spark.dynamicAllocation.shuffleTracking.enabled\", True)\\\n",
    "        .config(\"spark.shuffle.service.enabled\", False)\\\n",
    "        .config(\"spark.dynamicAllocation.executorIdleTimeout\",\"30s\")\\\n",
    "        .config(\"spark.driver.port\",9998)\\\n",
    "        .config(\"spark.blockManager.port\",10005)\\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Old API (RDD)\n",
    "spark_context = spark_session.sparkContext\n",
    "\n",
    "spark_context.setLogLevel(\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "888ce6be-c4b0-49da-b770-90c5d4f9d353",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/15 17:13:56 INFO InMemoryFileIndex: It took 11 ms to list leaf files for 1 paths.\n",
      "22/03/15 17:13:56 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 343.8 KiB, free 365.6 MiB)\n",
      "22/03/15 17:13:56 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 365.6 MiB)\n",
      "22/03/15 17:13:56 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on g11-project-master:10005 (size: 32.9 KiB, free: 366.2 MiB)\n",
      "22/03/15 17:13:56 INFO SparkContext: Created broadcast 11 from json at NativeMethodAccessorImpl.java:0\n",
      "22/03/15 17:13:56 INFO FileInputFormat: Total input files to process : 1\n",
      "22/03/15 17:13:56 INFO FileInputFormat: Total input files to process : 1\n",
      "22/03/15 17:13:56 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0\n",
      "22/03/15 17:13:56 INFO DAGScheduler: Got job 5 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "22/03/15 17:13:56 INFO DAGScheduler: Final stage: ResultStage 5 (json at NativeMethodAccessorImpl.java:0)\n",
      "22/03/15 17:13:56 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/03/15 17:13:56 INFO DAGScheduler: Missing parents: List()\n",
      "22/03/15 17:13:56 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[19] at json at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "22/03/15 17:13:56 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 8.6 KiB, free 365.5 MiB)\n",
      "22/03/15 17:13:56 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 365.5 MiB)\n",
      "22/03/15 17:13:56 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on g11-project-master:10005 (size: 4.7 KiB, free: 366.2 MiB)\n",
      "22/03/15 17:13:56 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1478\n",
      "22/03/15 17:13:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[19] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "22/03/15 17:13:56 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0\n",
      "22/03/15 17:13:57 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20220315170318-0038/5 on worker-20220312123152-192.168.2.197-35179 (192.168.2.197:35179) with 2 core(s)\n",
      "22/03/15 17:13:57 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1 for resource profile id: 0)\n",
      "22/03/15 17:13:57 INFO StandaloneSchedulerBackend: Granted executor ID app-20220315170318-0038/5 on hostPort 192.168.2.197:35179 with 2 core(s), 1024.0 MiB RAM\n",
      "22/03/15 17:13:57 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20220315170318-0038/5 is now RUNNING\n",
      "22/03/15 17:14:01 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.2.197:59660) with ID 5,  ResourceProfileId 0\n",
      "22/03/15 17:14:01 INFO ExecutorMonitor: New executor 5 has registered (new total is 2)\n",
      "22/03/15 17:14:01 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.2.197:10006 with 366.3 MiB RAM, BlockManagerId(5, 192.168.2.197, 10006, None)\n",
      "22/03/15 17:14:01 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (192.168.2.197, executor 5, partition 0, ANY, 4604 bytes) taskResourceAssignments Map()\n",
      "22/03/15 17:14:01 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 192.168.2.197:10006 (size: 4.7 KiB, free: 366.3 MiB)\n",
      "22/03/15 17:14:02 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 192.168.2.197:10006 (size: 32.9 KiB, free: 366.3 MiB)\n",
      "22/03/15 17:14:03 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 2503 ms on 192.168.2.197 (executor 5) (1/1)\n",
      "22/03/15 17:14:03 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool \n",
      "22/03/15 17:14:03 INFO DAGScheduler: ResultStage 5 (json at NativeMethodAccessorImpl.java:0) finished in 7.236 s\n",
      "22/03/15 17:14:03 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/03/15 17:14:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished\n",
      "22/03/15 17:14:03 INFO DAGScheduler: Job 5 finished: json at NativeMethodAccessorImpl.java:0, took 7.241599 s\n",
      "22/03/15 17:14:04 WARN CacheManager: Asked to cache already cached data.        \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'readlines'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhdfs://130.238.28.151:9000/user/ubuntu/Reddits_Comments\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m testJsonData \u001b[38;5;241m=\u001b[39m spark_session\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\\\n\u001b[1;32m      4\u001b[0m \u001b[38;5;241m.\u001b[39mjson(path)\\\n\u001b[1;32m      5\u001b[0m \u001b[38;5;241m.\u001b[39mcache()\n\u001b[0;32m----> 7\u001b[0m data \u001b[38;5;241m=\u001b[39m [json\u001b[38;5;241m.\u001b[39mloads(line) \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtestJsonData\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadlines\u001b[49m()]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/dataframe.py:1659\u001b[0m, in \u001b[0;36mDataFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1649\u001b[0m \u001b[38;5;124;03m\"\"\"Returns the :class:`Column` denoted by ``name``.\u001b[39;00m\n\u001b[1;32m   1650\u001b[0m \n\u001b[1;32m   1651\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1656\u001b[0m \u001b[38;5;124;03m[Row(age=2), Row(age=5)]\u001b[39;00m\n\u001b[1;32m   1657\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m-> 1659\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1660\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n\u001b[1;32m   1661\u001b[0m jc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mapply(name)\n\u001b[1;32m   1662\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Column(jc)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'readlines'"
     ]
    }
   ],
   "source": [
    "\n",
    "path = \"hdfs://130.238.28.151:9000/user/ubuntu/Reddits_Comments\"\n",
    "\n",
    "testJsonData = spark_session.read.option(\"multiline\", \"true\")\\\n",
    ".json(path)\\\n",
    ".cache()\n",
    "\n",
    "data = [json.loads(line) for line in testJsonData.readlines()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89a79b69-13bd-475e-a907-5ca22be6c991",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/15 17:19:11 INFO InMemoryFileIndex: It took 14 ms to list leaf files for 1 paths.\n",
      "22/03/15 17:19:11 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 343.8 KiB, free 365.6 MiB)\n",
      "22/03/15 17:19:11 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 365.6 MiB)\n",
      "22/03/15 17:19:11 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on g11-project-master:10005 (size: 32.9 KiB, free: 366.2 MiB)\n",
      "22/03/15 17:19:11 INFO SparkContext: Created broadcast 15 from json at NativeMethodAccessorImpl.java:0\n",
      "22/03/15 17:19:11 INFO FileInputFormat: Total input files to process : 1\n",
      "22/03/15 17:19:11 INFO FileInputFormat: Total input files to process : 1\n",
      "22/03/15 17:19:11 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0\n",
      "22/03/15 17:19:11 INFO DAGScheduler: Got job 7 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "22/03/15 17:19:11 INFO DAGScheduler: Final stage: ResultStage 7 (json at NativeMethodAccessorImpl.java:0)\n",
      "22/03/15 17:19:11 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/03/15 17:19:11 INFO DAGScheduler: Missing parents: List()\n",
      "22/03/15 17:19:11 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[25] at json at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "22/03/15 17:19:11 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 8.6 KiB, free 365.5 MiB)\n",
      "22/03/15 17:19:11 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 365.5 MiB)\n",
      "22/03/15 17:19:11 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on g11-project-master:10005 (size: 4.7 KiB, free: 366.2 MiB)\n",
      "22/03/15 17:19:11 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1478\n",
      "22/03/15 17:19:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[25] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "22/03/15 17:19:11 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0\n",
      "22/03/15 17:19:12 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20220315170318-0038/6 on worker-20220312123152-192.168.2.197-35179 (192.168.2.197:35179) with 2 core(s)\n",
      "22/03/15 17:19:12 INFO StandaloneSchedulerBackend: Granted executor ID app-20220315170318-0038/6 on hostPort 192.168.2.197:35179 with 2 core(s), 1024.0 MiB RAM\n",
      "22/03/15 17:19:12 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1 for resource profile id: 0)\n",
      "22/03/15 17:19:12 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20220315170318-0038/6 is now RUNNING\n",
      "22/03/15 17:19:15 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.2.197:59692) with ID 6,  ResourceProfileId 0\n",
      "22/03/15 17:19:15 INFO ExecutorMonitor: New executor 6 has registered (new total is 2)\n",
      "22/03/15 17:19:15 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.2.197:10006 with 366.3 MiB RAM, BlockManagerId(6, 192.168.2.197, 10006, None)\n",
      "22/03/15 17:19:15 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7) (192.168.2.197, executor 6, partition 0, ANY, 4604 bytes) taskResourceAssignments Map()\n",
      "22/03/15 17:19:16 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 192.168.2.197:10006 (size: 4.7 KiB, free: 366.3 MiB)\n",
      "22/03/15 17:19:17 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 192.168.2.197:10006 (size: 32.9 KiB, free: 366.3 MiB)\n",
      "22/03/15 17:19:18 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 2460 ms on 192.168.2.197 (executor 6) (1/1)\n",
      "22/03/15 17:19:18 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool \n",
      "22/03/15 17:19:18 INFO DAGScheduler: ResultStage 7 (json at NativeMethodAccessorImpl.java:0) finished in 6.623 s\n",
      "22/03/15 17:19:18 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/03/15 17:19:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished\n",
      "22/03/15 17:19:18 INFO DAGScheduler: Job 7 finished: json at NativeMethodAccessorImpl.java:0, took 6.633450 s\n",
      "22/03/15 17:19:18 WARN CacheManager: Asked to cache already cached data.        \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'readlines'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhdfs://130.238.28.151:9000/user/ubuntu/Reddits_Comments\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m testJsonData \u001b[38;5;241m=\u001b[39m spark_session\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\\\n\u001b[1;32m      4\u001b[0m \u001b[38;5;241m.\u001b[39mjson(path)\\\n\u001b[1;32m      5\u001b[0m \u001b[38;5;241m.\u001b[39mcache()\n\u001b[0;32m----> 7\u001b[0m data \u001b[38;5;241m=\u001b[39m [json\u001b[38;5;241m.\u001b[39mloads(line) \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtestJsonData\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadlines\u001b[49m()]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/dataframe.py:1659\u001b[0m, in \u001b[0;36mDataFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1649\u001b[0m \u001b[38;5;124;03m\"\"\"Returns the :class:`Column` denoted by ``name``.\u001b[39;00m\n\u001b[1;32m   1650\u001b[0m \n\u001b[1;32m   1651\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1656\u001b[0m \u001b[38;5;124;03m[Row(age=2), Row(age=5)]\u001b[39;00m\n\u001b[1;32m   1657\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m-> 1659\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1660\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n\u001b[1;32m   1661\u001b[0m jc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mapply(name)\n\u001b[1;32m   1662\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Column(jc)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'readlines'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/15 17:19:48 INFO StandaloneSchedulerBackend: Requesting to kill executor(s) 6\n",
      "22/03/15 17:19:48 INFO StandaloneSchedulerBackend: Actual list of executor(s) to be killed is 6\n",
      "22/03/15 17:19:48 INFO ExecutorAllocationManager: Executors 6 removed due to idle timeout.\n",
      "22/03/15 17:19:48 INFO TaskSchedulerImpl: Executor 6 on 192.168.2.197 killed by driver.\n",
      "22/03/15 17:19:48 INFO DAGScheduler: Executor lost: 6 (epoch 6)\n",
      "22/03/15 17:19:48 INFO BlockManagerMasterEndpoint: Trying to remove executor 6 from BlockManagerMaster.\n",
      "22/03/15 17:19:48 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(6, 192.168.2.197, 10006, None)\n",
      "22/03/15 17:19:48 INFO ExecutorMonitor: Executor 6 is removed. Remove reason statistics: (gracefully decommissioned: 0, decommision unfinished: 0, driver killed: 7, unexpectedly exited: 0).\n",
      "22/03/15 17:19:48 INFO BlockManagerMaster: Removed 6 successfully in removeExecutor\n",
      "22/03/15 17:19:48 INFO DAGScheduler: Shuffle files lost for executor: 6 (epoch 6)\n"
     ]
    }
   ],
   "source": [
    "path = \"hdfs://130.238.28.151:9000/user/ubuntu/Reddits_Comments\"\n",
    "\n",
    "testJsonData = spark_session.read.option(\"multiline\", \"true\")\\\n",
    ".json(path)\\\n",
    ".cache()\n",
    "\n",
    "data = [json.loads(line) for line in testJsonData.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bdebd08-731e-4a88-a25f-d8633d862485",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'hdfs://130.238.28.151:9000/user/ubuntu/Reddits_Comments'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhdfs://130.238.28.151:9000/user/ubuntu/Reddits_Comments\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m infile:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m infile\u001b[38;5;241m.\u001b[39mreadlines():\n\u001b[1;32m      6\u001b[0m         data\u001b[38;5;241m.\u001b[39mappend(json\u001b[38;5;241m.\u001b[39mloads(line))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'hdfs://130.238.28.151:9000/user/ubuntu/Reddits_Comments'"
     ]
    }
   ],
   "source": [
    "path = \"hdfs://130.238.28.151:9000/user/ubuntu/Reddits_Comments\"\n",
    "\n",
    "data = []\n",
    "with open(path, \"r\") as infile:\n",
    "    for line in infile.readlines():\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "print (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03d2b2f4-8987-444f-8e5f-84efa6cee1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/15 17:26:27 INFO InMemoryFileIndex: It took 17 ms to list leaf files for 1 paths.\n",
      "22/03/15 17:26:27 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 343.8 KiB, free 365.2 MiB)\n",
      "22/03/15 17:26:27 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 365.2 MiB)\n",
      "22/03/15 17:26:27 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on g11-project-master:10005 (size: 32.9 KiB, free: 366.2 MiB)\n",
      "22/03/15 17:26:27 INFO SparkContext: Created broadcast 17 from json at NativeMethodAccessorImpl.java:0\n",
      "22/03/15 17:26:27 INFO FileInputFormat: Total input files to process : 1\n",
      "22/03/15 17:26:27 INFO FileInputFormat: Total input files to process : 1\n",
      "22/03/15 17:26:27 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0\n",
      "22/03/15 17:26:27 INFO DAGScheduler: Got job 8 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "22/03/15 17:26:27 INFO DAGScheduler: Final stage: ResultStage 8 (json at NativeMethodAccessorImpl.java:0)\n",
      "22/03/15 17:26:27 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/03/15 17:26:27 INFO DAGScheduler: Missing parents: List()\n",
      "22/03/15 17:26:27 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[28] at json at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "22/03/15 17:26:27 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 8.6 KiB, free 365.2 MiB)\n",
      "22/03/15 17:26:27 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 365.2 MiB)\n",
      "22/03/15 17:26:27 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on g11-project-master:10005 (size: 4.7 KiB, free: 366.2 MiB)\n",
      "22/03/15 17:26:27 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1478\n",
      "22/03/15 17:26:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[28] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "22/03/15 17:26:27 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0\n",
      "22/03/15 17:26:28 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20220315170318-0038/7 on worker-20220312123152-192.168.2.197-35179 (192.168.2.197:35179) with 2 core(s)\n",
      "22/03/15 17:26:28 INFO StandaloneSchedulerBackend: Granted executor ID app-20220315170318-0038/7 on hostPort 192.168.2.197:35179 with 2 core(s), 1024.0 MiB RAM\n",
      "22/03/15 17:26:28 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1 for resource profile id: 0)\n",
      "22/03/15 17:26:28 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20220315170318-0038/7 is now RUNNING\n",
      "22/03/15 17:26:31 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.2.197:59720) with ID 7,  ResourceProfileId 0\n",
      "22/03/15 17:26:31 INFO ExecutorMonitor: New executor 7 has registered (new total is 2)\n",
      "22/03/15 17:26:31 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.2.197:10006 with 366.3 MiB RAM, BlockManagerId(7, 192.168.2.197, 10006, None)\n",
      "22/03/15 17:26:31 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8) (192.168.2.197, executor 7, partition 0, ANY, 4604 bytes) taskResourceAssignments Map()\n",
      "22/03/15 17:26:32 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 192.168.2.197:10006 (size: 4.7 KiB, free: 366.3 MiB)\n",
      "22/03/15 17:26:33 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 192.168.2.197:10006 (size: 32.9 KiB, free: 366.3 MiB)\n",
      "22/03/15 17:26:34 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 2496 ms on 192.168.2.197 (executor 7) (1/1)\n",
      "22/03/15 17:26:34 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool \n",
      "22/03/15 17:26:34 INFO DAGScheduler: ResultStage 8 (json at NativeMethodAccessorImpl.java:0) finished in 6.787 s\n",
      "22/03/15 17:26:34 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/03/15 17:26:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished\n",
      "22/03/15 17:26:34 INFO DAGScheduler: Job 8 finished: json at NativeMethodAccessorImpl.java:0, took 6.794872 s\n",
      "22/03/15 17:26:34 WARN CacheManager: Asked to cache already cached data.        \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'readlines'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m testJsonData \u001b[38;5;241m=\u001b[39m spark_session\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\\\n\u001b[1;32m      6\u001b[0m \u001b[38;5;241m.\u001b[39mjson(path)\\\n\u001b[1;32m      7\u001b[0m \u001b[38;5;241m.\u001b[39mcache()\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtestJsonData\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadlines\u001b[49m():\n\u001b[1;32m     10\u001b[0m     data\u001b[38;5;241m.\u001b[39mappend(json\u001b[38;5;241m.\u001b[39mloads(line))\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m (data)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/dataframe.py:1659\u001b[0m, in \u001b[0;36mDataFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1649\u001b[0m \u001b[38;5;124;03m\"\"\"Returns the :class:`Column` denoted by ``name``.\u001b[39;00m\n\u001b[1;32m   1650\u001b[0m \n\u001b[1;32m   1651\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1656\u001b[0m \u001b[38;5;124;03m[Row(age=2), Row(age=5)]\u001b[39;00m\n\u001b[1;32m   1657\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m-> 1659\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1660\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n\u001b[1;32m   1661\u001b[0m jc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mapply(name)\n\u001b[1;32m   1662\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Column(jc)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'readlines'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/15 17:26:54 ERROR StandaloneSchedulerBackend: Application has been killed. Reason: Master removed our application: KILLED\n",
      "22/03/15 17:26:54 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exiting due to error from cluster scheduler: Master removed our application: KILLED\n",
      "\tat org.apache.spark.scheduler.TaskSchedulerImpl.error(TaskSchedulerImpl.scala:919)\n",
      "\tat org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.dead(StandaloneSchedulerBackend.scala:154)\n",
      "\tat org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint.markDead(StandaloneAppClient.scala:262)\n",
      "\tat org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$receive$1.applyOrElse(StandaloneAppClient.scala:169)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:115)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/03/15 17:26:54 INFO SparkUI: Stopped Spark web UI at http://g11-project-master:4040\n",
      "22/03/15 17:26:54 ERROR TaskSchedulerImpl: Lost executor 7 on 192.168.2.197: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/03/15 17:26:54 INFO DAGScheduler: Executor lost: 7 (epoch 7)\n",
      "22/03/15 17:26:54 INFO BlockManagerMasterEndpoint: Trying to remove executor 7 from BlockManagerMaster.\n",
      "22/03/15 17:26:54 INFO ExecutorMonitor: Executor 7 is removed. Remove reason statistics: (gracefully decommissioned: 0, decommision unfinished: 0, driver killed: 7, unexpectedly exited: 1).\n",
      "22/03/15 17:26:54 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(7, 192.168.2.197, 10006, None)\n",
      "22/03/15 17:26:54 INFO BlockManagerMaster: Removed 7 successfully in removeExecutor\n",
      "22/03/15 17:26:54 INFO DAGScheduler: Shuffle files lost for executor: 7 (epoch 7)\n",
      "22/03/15 17:26:54 INFO StandaloneSchedulerBackend: Shutting down all executors\n",
      "22/03/15 17:26:54 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down\n",
      "22/03/15 17:26:54 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\n",
      "22/03/15 17:26:54 INFO MemoryStore: MemoryStore cleared\n",
      "22/03/15 17:26:54 INFO BlockManager: BlockManager stopped\n",
      "22/03/15 17:26:54 INFO BlockManagerMaster: BlockManagerMaster stopped\n",
      "22/03/15 17:26:54 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\n",
      "22/03/15 17:26:54 INFO SparkContext: Successfully stopped SparkContext\n"
     ]
    }
   ],
   "source": [
    "path = \"hdfs://130.238.28.151:9000/user/ubuntu/Reddits_Comments\"\n",
    "\n",
    "data = []\n",
    "\n",
    "testJsonData = spark_session.read.option(\"multiline\", \"true\")\\\n",
    ".json(path)\\\n",
    ".cache()\n",
    "\n",
    "for line in testJsonData.readlines():\n",
    "    data.append(json.loads(line))\n",
    "\n",
    "print (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec29255-6991-4b13-be57-d7c24b9fd6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Python object from JSON string data\n",
    "obj = json.loads(json_data)\n",
    "  \n",
    "# Pretty Print JSON\n",
    "json_formatted_str = json.dumps(obj, indent=4)\n",
    "print(json_formatted_str)\n",
    "\n",
    "resultlist_json = [json.loads(x) for x in resultlist] \n",
    "print(json.dumps(resultlist_json, sort_keys=True, indent=4))\n",
    "\n",
    "\n",
    "\n",
    "df = spark_session.read.option(\"header\", \"true\")\\\n",
    ".csv(\"hdfs://192.168.2.119:9000/parking-citations.csv\")\\\n",
    ".cache()\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "382535d2-5fef-4926-9a65-58da853f4609",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/15 14:01:29 INFO InMemoryFileIndex: It took 8 ms to list leaf files for 1 paths.\n",
      "22/03/15 14:01:29 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 343.8 KiB, free 364.1 MiB)\n",
      "22/03/15 14:01:29 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 364.0 MiB)\n",
      "22/03/15 14:01:29 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on g11-project-master:10005 (size: 32.9 KiB, free: 366.1 MiB)\n",
      "22/03/15 14:01:29 INFO SparkContext: Created broadcast 51 from json at <unknown>:0\n",
      "22/03/15 14:01:29 INFO FileInputFormat: Total input files to process : 1\n",
      "22/03/15 14:01:29 INFO FileInputFormat: Total input files to process : 1\n",
      "22/03/15 14:01:29 INFO SparkContext: Starting job: json at <unknown>:0\n",
      "22/03/15 14:01:29 INFO DAGScheduler: Got job 23 (json at <unknown>:0) with 1 output partitions\n",
      "22/03/15 14:01:29 INFO DAGScheduler: Final stage: ResultStage 23 (json at <unknown>:0)\n",
      "22/03/15 14:01:29 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/03/15 14:01:29 INFO DAGScheduler: Missing parents: List()\n",
      "22/03/15 14:01:29 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[87] at json at <unknown>:0), which has no missing parents\n",
      "22/03/15 14:01:29 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 8.6 KiB, free 364.0 MiB)\n",
      "22/03/15 14:01:29 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 364.0 MiB)\n",
      "22/03/15 14:01:29 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on g11-project-master:10005 (size: 4.7 KiB, free: 366.1 MiB)\n",
      "22/03/15 14:01:29 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1478\n",
      "22/03/15 14:01:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[87] at json at <unknown>:0) (first 15 tasks are for partitions Vector(0))\n",
      "22/03/15 14:01:29 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks resource profile 0\n",
      "22/03/15 14:01:30 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1 for resource profile id: 0)\n",
      "22/03/15 14:01:30 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20220315123638-0037/18 on worker-20220312123152-192.168.2.197-35179 (192.168.2.197:35179) with 2 core(s)\n",
      "22/03/15 14:01:30 INFO StandaloneSchedulerBackend: Granted executor ID app-20220315123638-0037/18 on hostPort 192.168.2.197:35179 with 2 core(s), 1024.0 MiB RAM\n",
      "22/03/15 14:01:30 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20220315123638-0037/18 is now RUNNING\n",
      "22/03/15 14:01:33 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.2.197:58838) with ID 18,  ResourceProfileId 0\n",
      "22/03/15 14:01:33 INFO ExecutorMonitor: New executor 18 has registered (new total is 2)\n",
      "22/03/15 14:01:33 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.2.197:10006 with 366.3 MiB RAM, BlockManagerId(18, 192.168.2.197, 10006, None)\n",
      "22/03/15 14:01:33 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 33) (192.168.2.197, executor 18, partition 0, ANY, 4604 bytes) taskResourceAssignments Map()\n",
      "22/03/15 14:01:33 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 192.168.2.197:10006 (size: 4.7 KiB, free: 366.3 MiB)\n",
      "22/03/15 14:01:34 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 192.168.2.197:10006 (size: 32.9 KiB, free: 366.3 MiB)\n",
      "22/03/15 14:01:35 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 33) in 2372 ms on 192.168.2.197 (executor 18) (1/1)\n",
      "22/03/15 14:01:35 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool \n",
      "22/03/15 14:01:35 INFO DAGScheduler: ResultStage 23 (json at <unknown>:0) finished in 6.596 s\n",
      "22/03/15 14:01:35 INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/03/15 14:01:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 23: Stage finished\n",
      "22/03/15 14:01:35 INFO DAGScheduler: Job 23 finished: json at <unknown>:0, took 6.601742 s\n",
      "22/03/15 14:01:35 WARN CacheManager: Asked to cache already cached data.        \n",
      "22/03/15 14:02:05 INFO StandaloneSchedulerBackend: Requesting to kill executor(s) 18\n",
      "22/03/15 14:02:05 INFO StandaloneSchedulerBackend: Actual list of executor(s) to be killed is 18\n",
      "22/03/15 14:02:05 INFO ExecutorAllocationManager: Executors 18 removed due to idle timeout.\n",
      "22/03/15 14:02:05 INFO TaskSchedulerImpl: Executor 18 on 192.168.2.197 killed by driver.\n",
      "22/03/15 14:02:05 INFO DAGScheduler: Executor lost: 18 (epoch 18)\n",
      "22/03/15 14:02:05 INFO ExecutorMonitor: Executor 18 is removed. Remove reason statistics: (gracefully decommissioned: 0, decommision unfinished: 0, driver killed: 19, unexpectedly exited: 0).\n",
      "22/03/15 14:02:05 INFO BlockManagerMasterEndpoint: Trying to remove executor 18 from BlockManagerMaster.\n",
      "22/03/15 14:02:05 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(18, 192.168.2.197, 10006, None)\n",
      "22/03/15 14:02:05 INFO BlockManagerMaster: Removed 18 successfully in removeExecutor\n",
      "22/03/15 14:02:05 INFO DAGScheduler: Shuffle files lost for executor: 18 (epoch 18)\n"
     ]
    }
   ],
   "source": [
    "parser = json.JSONDecoder()\n",
    "parsed = []  # a list to hold individually parsed JSON structures\n",
    "\n",
    "#with open('test.json') as f:\n",
    "    #data = f.read()\n",
    "    \n",
    "data = spark_session.read.option(\"multiline\", \"true\")\\\n",
    ".json(path)\\\n",
    ".cache()  \n",
    "\n",
    "parsed = []\n",
    "\n",
    "parsed.append(data.replace(\"}\",\"},\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3d14f1f9-22c9-4c3f-aa8c-59622ca8088f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[_corrupt_record: string]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/15 14:06:39 INFO BlockManagerInfo: Removed broadcast_44_piece0 on g11-project-master:10005 in memory (size: 4.7 KiB, free: 366.1 MiB)\n",
      "22/03/15 14:06:39 INFO BlockManagerInfo: Removed broadcast_52_piece0 on g11-project-master:10005 in memory (size: 4.7 KiB, free: 366.1 MiB)\n",
      "22/03/15 14:06:39 INFO BlockManagerInfo: Removed broadcast_46_piece0 on g11-project-master:10005 in memory (size: 4.7 KiB, free: 366.1 MiB)\n",
      "22/03/15 14:06:39 INFO BlockManagerInfo: Removed broadcast_43_piece0 on g11-project-master:10005 in memory (size: 32.9 KiB, free: 366.1 MiB)\n",
      "22/03/15 14:06:39 INFO BlockManagerInfo: Removed broadcast_50_piece0 on g11-project-master:10005 in memory (size: 4.7 KiB, free: 366.1 MiB)\n",
      "22/03/15 14:06:39 INFO BlockManagerInfo: Removed broadcast_47_piece0 on g11-project-master:10005 in memory (size: 32.9 KiB, free: 366.2 MiB)\n",
      "22/03/15 14:06:39 INFO BlockManagerInfo: Removed broadcast_51_piece0 on g11-project-master:10005 in memory (size: 32.9 KiB, free: 366.2 MiB)\n",
      "22/03/15 14:06:39 INFO BlockManagerInfo: Removed broadcast_48_piece0 on g11-project-master:10005 in memory (size: 4.7 KiB, free: 366.2 MiB)\n",
      "22/03/15 14:06:39 INFO BlockManagerInfo: Removed broadcast_49_piece0 on g11-project-master:10005 in memory (size: 32.9 KiB, free: 366.2 MiB)\n",
      "22/03/15 14:06:39 INFO BlockManagerInfo: Removed broadcast_45_piece0 on g11-project-master:10005 in memory (size: 32.9 KiB, free: 366.3 MiB)\n",
      "22/03/15 14:10:19 ERROR StandaloneSchedulerBackend: Application has been killed. Reason: Master removed our application: KILLED\n",
      "22/03/15 14:10:19 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exiting due to error from cluster scheduler: Master removed our application: KILLED\n",
      "\tat org.apache.spark.scheduler.TaskSchedulerImpl.error(TaskSchedulerImpl.scala:919)\n",
      "\tat org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.dead(StandaloneSchedulerBackend.scala:154)\n",
      "\tat org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint.markDead(StandaloneAppClient.scala:262)\n",
      "\tat org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$receive$1.applyOrElse(StandaloneAppClient.scala:169)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:115)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/03/15 14:10:19 INFO SparkUI: Stopped Spark web UI at http://g11-project-master:4040\n",
      "22/03/15 14:10:19 INFO StandaloneSchedulerBackend: Shutting down all executors\n",
      "22/03/15 14:10:19 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down\n",
      "22/03/15 14:10:19 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\n",
      "22/03/15 14:10:19 INFO MemoryStore: MemoryStore cleared\n",
      "22/03/15 14:10:19 INFO BlockManager: BlockManager stopped\n",
      "22/03/15 14:10:19 INFO BlockManagerMaster: BlockManagerMaster stopped\n",
      "22/03/15 14:10:19 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\n",
      "22/03/15 14:10:19 INFO SparkContext: Successfully stopped SparkContext\n"
     ]
    }
   ],
   "source": [
    "print(parsed[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88fa8576-499b-4b7f-bb9f-7fe7846d7c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/15 18:30:53 INFO InMemoryFileIndex: It took 98 ms to list leaf files for 1 paths.\n",
      "22/03/15 18:30:53 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 343.8 KiB, free 366.0 MiB)\n",
      "22/03/15 18:30:53 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 365.9 MiB)\n",
      "22/03/15 18:30:53 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on g11-project-master:10005 (size: 32.9 KiB, free: 366.3 MiB)\n",
      "22/03/15 18:30:53 INFO SparkContext: Created broadcast 0 from json at NativeMethodAccessorImpl.java:0\n",
      "22/03/15 18:30:54 INFO FileInputFormat: Total input files to process : 1\n",
      "22/03/15 18:30:54 INFO FileInputFormat: Total input files to process : 1\n",
      "22/03/15 18:30:54 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0\n",
      "22/03/15 18:30:54 INFO DAGScheduler: Got job 0 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "22/03/15 18:30:54 INFO DAGScheduler: Final stage: ResultStage 0 (json at NativeMethodAccessorImpl.java:0)\n",
      "22/03/15 18:30:54 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/03/15 18:30:54 INFO DAGScheduler: Missing parents: List()\n",
      "22/03/15 18:30:54 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[2] at json at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "22/03/15 18:30:54 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 8.6 KiB, free 365.9 MiB)\n",
      "22/03/15 18:30:54 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 365.9 MiB)\n",
      "22/03/15 18:30:54 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on g11-project-master:10005 (size: 4.7 KiB, free: 366.3 MiB)\n",
      "22/03/15 18:30:54 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478\n",
      "22/03/15 18:30:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "22/03/15 18:30:54 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0\n",
      "22/03/15 18:30:55 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20220315183046-0039/0 on worker-20220312123152-192.168.2.197-35179 (192.168.2.197:35179) with 2 core(s)\n",
      "22/03/15 18:30:55 INFO StandaloneSchedulerBackend: Granted executor ID app-20220315183046-0039/0 on hostPort 192.168.2.197:35179 with 2 core(s), 1024.0 MiB RAM\n",
      "22/03/15 18:30:55 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1 for resource profile id: 0)\n",
      "22/03/15 18:30:55 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20220315183046-0039/0 is now RUNNING\n",
      "22/03/15 18:30:59 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.2.197:60396) with ID 0,  ResourceProfileId 0\n",
      "22/03/15 18:30:59 INFO ExecutorMonitor: New executor 0 has registered (new total is 2)\n",
      "22/03/15 18:30:59 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.2.197:10006 with 366.3 MiB RAM, BlockManagerId(0, 192.168.2.197, 10006, None)\n",
      "22/03/15 18:30:59 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (192.168.2.197, executor 0, partition 0, ANY, 4604 bytes) taskResourceAssignments Map()\n",
      "22/03/15 18:30:59 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.2.197:10006 (size: 4.7 KiB, free: 366.3 MiB)\n",
      "22/03/15 18:31:00 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.2.197:10006 (size: 32.9 KiB, free: 366.3 MiB)\n",
      "22/03/15 18:31:01 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2633 ms on 192.168.2.197 (executor 0) (1/1)\n",
      "22/03/15 18:31:01 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool \n",
      "22/03/15 18:31:02 INFO DAGScheduler: ResultStage 0 (json at NativeMethodAccessorImpl.java:0) finished in 7.379 s\n",
      "22/03/15 18:31:02 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/03/15 18:31:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished\n",
      "22/03/15 18:31:02 INFO DAGScheduler: Job 0 finished: json at NativeMethodAccessorImpl.java:0, took 7.511646 s\n",
      "22/03/15 18:31:03 INFO BlockManagerInfo: Removed broadcast_1_piece0 on g11-project-master:10005 in memory (size: 4.7 KiB, free: 366.3 MiB)\n",
      "22/03/15 18:31:03 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.2.197:10006 in memory (size: 4.7 KiB, free: 366.3 MiB)\n",
      "22/03/15 18:31:03 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 192.168.2.197:10006 in memory (size: 32.9 KiB, free: 366.3 MiB)\n",
      "22/03/15 18:31:03 INFO BlockManagerInfo: Removed broadcast_0_piece0 on g11-project-master:10005 in memory (size: 32.9 KiB, free: 366.3 MiB)\n",
      "22/03/15 18:31:04 INFO FileSourceStrategy: Pushed Filters: \n",
      "22/03/15 18:31:04 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "22/03/15 18:31:04 INFO FileSourceStrategy: Output Data Schema: struct<_corrupt_record: string>\n"
     ]
    }
   ],
   "source": [
    "path = \"hdfs://130.238.28.151:9000/user/ubuntu/Reddits_Comments\"\n",
    "#data = spark_session.read.json(path)\n",
    "\n",
    "testJsonData = spark_session.read.option(\"multiline\", \"true\")\\\n",
    ".json(path)\\\n",
    ".cache()\n",
    "\n",
    "#testJsonData.toJSON()\n",
    "\n",
    "\n",
    "#obj = json.load(testJsonData)\n",
    "\n",
    "#df= testJsonData.to_json()\n",
    "\n",
    "#json_formatted_str = json.dumps(testJsonData, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "505f7b13-56ef-4b60-9d7e-68f440ba8aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/15 18:31:47 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 339.5 KiB, free 366.0 MiB)\n",
      "22/03/15 18:31:47 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.8 KiB, free 365.9 MiB)\n",
      "22/03/15 18:31:47 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on g11-project-master:10005 (size: 32.8 KiB, free: 366.3 MiB)\n",
      "22/03/15 18:31:47 INFO SparkContext: Created broadcast 2 from showString at NativeMethodAccessorImpl.java:0\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "\nSince Spark 2.3, the queries from raw JSON/CSV files are disallowed when the\nreferenced columns only include the internal corrupt record column\n(named _corrupt_record by default). For example:\nspark.read.schema(schema).csv(file).filter($\"_corrupt_record\".isNotNull).count()\nand spark.read.schema(schema).csv(file).select(\"_corrupt_record\").show().\nInstead, you can cache or save the parsed results and then send the same query.\nFor example, val df = spark.read.schema(schema).csv(file).cache() and then\ndf.filter($\"_corrupt_record\".isNotNull).count().\n      ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtestJsonData\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/dataframe.py:494\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    491\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be a bool\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(truncate, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m truncate:\n\u001b[0;32m--> 494\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    496\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py:1309\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1304\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1305\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1306\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1308\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1309\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1310\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1313\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/utils.py:117\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    113\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: \nSince Spark 2.3, the queries from raw JSON/CSV files are disallowed when the\nreferenced columns only include the internal corrupt record column\n(named _corrupt_record by default). For example:\nspark.read.schema(schema).csv(file).filter($\"_corrupt_record\".isNotNull).count()\nand spark.read.schema(schema).csv(file).select(\"_corrupt_record\").show().\nInstead, you can cache or save the parsed results and then send the same query.\nFor example, val df = spark.read.schema(schema).csv(file).cache() and then\ndf.filter($\"_corrupt_record\".isNotNull).count().\n      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/15 19:00:47 INFO BlockManagerInfo: Removed broadcast_2_piece0 on g11-project-master:10005 in memory (size: 32.8 KiB, free: 366.3 MiB)\n"
     ]
    }
   ],
   "source": [
    "testJsonData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82dddff2-a29b-4da6-839c-6819e45755e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "#testJsonData.count()\n",
    "\n",
    "print(type(testJsonData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0688ed44-2630-46c6-8926-890a5f6efe27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _corrupt_record: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testJsonData.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "489e34a2-c000-47cf-9795-89a2df4c3dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/15 13:18:27 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 339.5 KiB, free 363.6 MiB)\n",
      "22/03/15 13:18:27 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 32.8 KiB, free 363.5 MiB)\n",
      "22/03/15 13:18:27 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on g11-project-master:10005 (size: 32.8 KiB, free: 366.0 MiB)\n",
      "22/03/15 13:18:27 INFO SparkContext: Created broadcast 36 from showString at NativeMethodAccessorImpl.java:0\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "\nSince Spark 2.3, the queries from raw JSON/CSV files are disallowed when the\nreferenced columns only include the internal corrupt record column\n(named _corrupt_record by default). For example:\nspark.read.schema(schema).csv(file).filter($\"_corrupt_record\".isNotNull).count()\nand spark.read.schema(schema).csv(file).select(\"_corrupt_record\").show().\nInstead, you can cache or save the parsed results and then send the same query.\nFor example, val df = spark.read.schema(schema).csv(file).cache() and then\ndf.filter($\"_corrupt_record\".isNotNull).count().\n      ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtestJsonData\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/dataframe.py:494\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    491\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be a bool\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(truncate, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m truncate:\n\u001b[0;32m--> 494\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    496\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py:1309\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1304\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1305\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1306\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1308\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1309\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1310\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1313\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/utils.py:117\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    113\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: \nSince Spark 2.3, the queries from raw JSON/CSV files are disallowed when the\nreferenced columns only include the internal corrupt record column\n(named _corrupt_record by default). For example:\nspark.read.schema(schema).csv(file).filter($\"_corrupt_record\".isNotNull).count()\nand spark.read.schema(schema).csv(file).select(\"_corrupt_record\").show().\nInstead, you can cache or save the parsed results and then send the same query.\nFor example, val df = spark.read.schema(schema).csv(file).cache() and then\ndf.filter($\"_corrupt_record\".isNotNull).count().\n      "
     ]
    }
   ],
   "source": [
    "testJsonData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0fff9791-e262-4a4d-87f6-6bad1f2786c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testJsonData.select(\"body\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efac058c-705b-4bc3-810c-248ce7c8e0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_context.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703f4022-d7ea-4a0d-bb1a-3cb856795577",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
