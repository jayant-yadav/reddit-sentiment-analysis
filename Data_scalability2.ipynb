{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9a89af7-11de-4ea7-a1a0-0ff244e97626",
   "metadata": {},
   "source": [
    "## Data size = 5.26 GB (RC_2010-01 & RC_2010-01 & RC_2010-07), Node = 4 (1 master + 3 workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b42d13aa-a23b-4972-a75a-4a878f3b0b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import time\n",
    "# packacges that needs to be installed across all nodes:\n",
    "from textblob import TextBlob \n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "929c1258-4ea9-488e-a23e-11c7c86dae2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/03/18 23:18:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/03/18 23:18:22 WARN ExecutorAllocationManager: Dynamic allocation without a shuffle service is an experimental feature.\n"
     ]
    }
   ],
   "source": [
    "spark_session = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"spark://192.168.2.197:7077\") \\\n",
    "        .appName(\"project_code_uc\")\\\n",
    "        .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "        .config(\"spark.dynamicAllocation.shuffleTracking.enabled\",True)\\\n",
    "        .config(\"spark.shuffle.service.enabled\", False)\\\n",
    "        .config(\"spark.dynamicAllocation.executorIdleTimeout\",\"30s\")\\\n",
    "        .config(\"spark.executor.cores\",2)\\\n",
    "        .config(\"spark.driver.port\",9998)\\\n",
    "        .config(\"spark.blockManager.port\",10005)\\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Old API (RDD)\n",
    "spark_context = spark_session.sparkContext\n",
    "\n",
    "spark_context.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3056ff9d-7cbe-4aa0-adca-0e7fce26a8a2",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1424411-dd56-4069-9fdc-e8ab35e477ce",
   "metadata": {},
   "source": [
    "## Start time count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b950093f-39b9-435b-96f1-4ad6b3cd4b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e9d0b95-68f4-45a5-8de4-87fe9086bb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data_frame = spark_session.read\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .json('hdfs://192.168.2.197:9000/user/hadoop/RC_2010-0*')\\\n",
    "    .cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150b68ce-9c20-44c5-be5c-72612cf1d0b4",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285833fd-7a0d-48f1-9736-7c58f0cb1bc7",
   "metadata": {},
   "source": [
    "## Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d55917f7-c9d9-4cd6-8fbb-cc82c3bf0ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Cleaning text before analysis\n",
    "\n",
    "rcb_df = data_frame.select('body')\n",
    "rcb_df = rcb_df.dropna()\n",
    "rcb_df = rcb_df.filter(rcb_df['body'] != '[deleted]')\n",
    "\n",
    "#removing stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = stopwords.words(\"english\")\n",
    "\n",
    "def remove_stopwords_fnc(x):        \n",
    "    text = ''\n",
    "    for x in x.split(' '):\n",
    "        if x.lower() not in stop_words:\n",
    "            text += x + ' '\n",
    "        else:\n",
    "            pass\n",
    "    return text\n",
    "\n",
    "remove_stopwords_udf = udf(remove_stopwords_fnc)\n",
    "spark_session.udf.register(\"remove_stopwords_udf\", remove_stopwords_udf)\n",
    "rcb_df = rcb_df.withColumn('body',remove_stopwords_udf('body'))\n",
    "\n",
    "# rcb_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec0c575c-dc13-4ef6-886d-ca04c7b4d167",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                body|     sentiment_score|\n",
      "+--------------------+--------------------+\n",
      "|Good rant, stop l...| 0.11613636363636362|\n",
      "|    Sounds good me. |                 0.7|\n",
      "|Ok people donate ...| 0.04999999999999999|\n",
      "|               red? |                 0.0|\n",
      "|really want give ...| 0.02938311688311688|\n",
      "|school, depends p...| 0.13333333333333333|\n",
      "|they?  know recen...| 0.16666666666666666|\n",
      "|I'll add voice. b...|                -0.5|\n",
      "|        worry 2012. |                 0.0|\n",
      "|[George Carlin sa...|              0.1875|\n",
      "|No, like that. He...|                 0.0|\n",
      "|sad her.  been. k...|-0.28214285714285714|\n",
      "|realize 'assclown...|                -0.1|\n",
      "|sure wants back. ...| 0.06643518518518518|\n",
      "|cat consider dog ...|                 0.0|\n",
      "|hate uninformed r...|-0.05510204081632656|\n",
      "|No, found sack po...|               -0.75|\n",
      "|Feds take fall fi...|0.024999999999999994|\n",
      "|   to, omgomgomgomg |                 0.0|\n",
      "|moved quite bit a...| 0.11666666666666665|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def sentiment_fnc(text):\n",
    "    return TextBlob(text).sentiment.polarity #gives the polarity of the sentiment, [-1.0, 1.0]\n",
    "    \n",
    "\n",
    "sentiment_udf = udf(lambda x: sentiment_fnc(x)) \n",
    "spark_session.udf.register(\"sentiment_udf\", sentiment_udf)\n",
    "rcb_df = rcb_df.withColumn('sentiment_score',sentiment_udf('body').cast('double'))\n",
    "\n",
    "rcb_df.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b940d368-0a4b-4c3f-9d46-6a1aee212246",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e927c9b5-dfbb-46c2-bb31-8e51486ed441",
   "metadata": {},
   "source": [
    "### The discussion topics on a subreddit using keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34ba4abc-dd99-4447-9f51-4087ea7761a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 20 kindest subreddits based on average comment score are:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------+\n",
      "|        subreddit|        avg(score)|\n",
      "+-----------------+------------------+\n",
      "|         DateRape|             59.25|\n",
      "|           raerth| 52.63157894736842|\n",
      "|       bestof2009|41.943885653785074|\n",
      "|arboriculturalist|              27.0|\n",
      "|     aqua_aqua_bh|              16.0|\n",
      "|           USPE08|10.533333333333333|\n",
      "|    announcements|10.315153938424631|\n",
      "|           treees|              10.0|\n",
      "|         moonhoax|               8.0|\n",
      "|        YourMoney|               8.0|\n",
      "|        introvert| 7.838709677419355|\n",
      "|             blog| 7.721166032953105|\n",
      "|             rand|               7.0|\n",
      "|           lonely|               7.0|\n",
      "|       notetoself|               6.8|\n",
      "|            gamin|               6.5|\n",
      "|            funny| 6.298935423958595|\n",
      "|   squidsgonewild|               6.0|\n",
      "|       Starcraft3|               6.0|\n",
      "|        Youngluck|              5.88|\n",
      "+-----------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "avg_subreddit_score = data_frame.groupBy(\"subreddit\").agg({'score': 'avg'})\n",
    "avg_subreddit_score_sorted = avg_subreddit_score.orderBy('avg(score)',ascending = False)\n",
    "print(\"The top 20 kindest subreddits based on average comment score are:\")\n",
    "avg_subreddit_score_sorted.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c6b37e-189a-4ca8-9d34-cbfd9015d33e",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e25666d-7d7e-4c4c-a0ac-ffe090b35d30",
   "metadata": {},
   "source": [
    "### What are the most active subreddits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3463637-a105-4171-a3bf-115dd55c59ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subreddit = data_frame.select('subreddit')\n",
    "df_subreddit = df_subreddit.dropna()\n",
    "df_subreddit_frequency = df_subreddit.groupby(\"subreddit\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "464d13cd-558b-4f3b-ae4c-8bac4f0ecb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:=======================================================> (42 + 1) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+\n",
      "|          subreddit|  count|\n",
      "+-------------------+-------+\n",
      "|          AskReddit|2035203|\n",
      "|         reddit.com| 850627|\n",
      "|               pics| 727446|\n",
      "|           politics| 436090|\n",
      "|               IAmA| 431667|\n",
      "|             gaming| 405058|\n",
      "|                WTF| 352414|\n",
      "|              funny| 275133|\n",
      "|            atheism| 232400|\n",
      "|            science| 199940|\n",
      "|          worldnews| 188371|\n",
      "|        programming| 178989|\n",
      "|         technology| 133420|\n",
      "|              trees| 103744|\n",
      "|    DoesAnybodyElse| 101413|\n",
      "|fffffffuuuuuuuuuuuu|  91035|\n",
      "|              Music|  87451|\n",
      "|relationship_advice|  79068|\n",
      "|    TwoXChromosomes|  78611|\n",
      "|             videos|  69644|\n",
      "+-------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_subreddit_f = df_subreddit_frequency.sort('count',ascending=False).show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb45b7a9-1e5e-4b4c-a7ea-00d725e5a30a",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cb2df8-a557-4853-b3c1-3b390538f6dd",
   "metadata": {},
   "source": [
    "## Execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f47d47ba-909a-4f82-b9e3-9acee888e2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 104.30300521850586\n"
     ]
    }
   ],
   "source": [
    "print(f\"Execution time: {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f042798-0428-4cc8-8e91-371f70e8339a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
