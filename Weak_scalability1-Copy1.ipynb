{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9a89af7-11de-4ea7-a1a0-0ff244e97626",
   "metadata": {},
   "source": [
    "# Reddit Comment Analysis\n",
    "### Data size = 3.78 GB (RC_2010-01 (1.58 GB)+ RC_2010-07 (2.2 GB))\n",
    "### Nodes = 1 (1 master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b42d13aa-a23b-4972-a75a-4a878f3b0b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import time\n",
    "# packages that needs to be installed across all nodes:\n",
    "from textblob import TextBlob \n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "929c1258-4ea9-488e-a23e-11c7c86dae2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/03/19 17:37:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/03/19 17:37:51 WARN ExecutorAllocationManager: Dynamic allocation without a shuffle service is an experimental feature.\n"
     ]
    }
   ],
   "source": [
    "spark_session = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"spark://192.168.2.197:7077\") \\\n",
    "        .appName(\"rc_analysis\")\\\n",
    "        .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "        .config(\"spark.dynamicAllocation.shuffleTracking.enabled\",True)\\\n",
    "        .config(\"spark.shuffle.service.enabled\", False)\\\n",
    "        .config(\"spark.dynamicAllocation.executorIdleTimeout\",\"30s\")\\\n",
    "        .config(\"spark.executor.cores\",2)\\\n",
    "        .config(\"spark.cores.max\", \"2\")\\\n",
    "        .config(\"spark.driver.port\",9998)\\\n",
    "        .config(\"spark.blockManager.port\",10005)\\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Old API (RDD)\n",
    "spark_context = spark_session.sparkContext\n",
    "\n",
    "spark_context.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3056ff9d-7cbe-4aa0-adca-0e7fce26a8a2",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1424411-dd56-4069-9fdc-e8ab35e477ce",
   "metadata": {},
   "source": [
    "## Start time count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b950093f-39b9-435b-96f1-4ad6b3cd4b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e9d0b95-68f4-45a5-8de4-87fe9086bb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data_frame = spark_session.read\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .json('hdfs://192.168.2.197:9000/user/hadoop/RC_2010-0*')\\\n",
    "    .cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de87edf-21ac-4254-aff8-07b3044233a6",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee83be35-2720-4e33-a1cc-a1e80e7626f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = data_frame.select('subreddit','body','score')\n",
    "data_frame = data_frame.dropna(how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150b68ce-9c20-44c5-be5c-72612cf1d0b4",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285833fd-7a0d-48f1-9736-7c58f0cb1bc7",
   "metadata": {},
   "source": [
    "## Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d55917f7-c9d9-4cd6-8fbb-cc82c3bf0ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Cleaning text before analysis\n",
    "\n",
    "rcb_df = data_frame.filter(data_frame['body'] != '[deleted]')\n",
    "\n",
    "#removing stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = stopwords.words(\"english\")\n",
    "\n",
    "def remove_stopwords_fnc(x):        \n",
    "    text = ''\n",
    "    for x in x.split(' '):\n",
    "        if x.lower() not in stop_words:\n",
    "            text += x + ' '\n",
    "        else:\n",
    "            pass\n",
    "    return text\n",
    "\n",
    "remove_stopwords_udf = udf(remove_stopwords_fnc)\n",
    "spark_session.udf.register(\"remove_stopwords_udf\", remove_stopwords_udf)\n",
    "rcb_df = rcb_df.withColumn('body',remove_stopwords_udf('body'))\n",
    "\n",
    "# rcb_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec0c575c-dc13-4ef6-886d-ca04c7b4d167",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+-----+--------------------+\n",
      "|          subreddit|                body|score|     sentiment_score|\n",
      "+-------------------+--------------------+-----+--------------------+\n",
      "|           politics|Good rant, stop l...|    5| 0.11613636363636362|\n",
      "|            offbeat|    Sounds good me. |    2|                 0.7|\n",
      "|             gaming|Ok people donate ...|    1| 0.04999999999999999|\n",
      "|           gonewild|               red? |   -1|                 0.0|\n",
      "|               IAmA|really want give ...|    2| 0.02938311688311688|\n",
      "|                WTF|school, depends p...|    1| 0.13333333333333333|\n",
      "|                WTF|they?  know recen...|    2| 0.16666666666666666|\n",
      "|         MensRights|I'll add voice. b...|    2|                -0.5|\n",
      "|               pics|        worry 2012. |    3|                 0.0|\n",
      "|              funny|[George Carlin sa...|   69|              0.1875|\n",
      "|              funny|No, like that. He...|   51|                 0.0|\n",
      "|          AskReddit|sad her.  been. k...|    2|-0.28214285714285714|\n",
      "|         reddit.com|realize 'assclown...|    7|                -0.1|\n",
      "|relationship_advice|sure wants back. ...|    2| 0.06643518518518518|\n",
      "|         reddit.com|cat consider dog ...|    1|                 0.0|\n",
      "|           politics|hate uninformed r...|    2|-0.05510204081632656|\n",
      "|         reddit.com|No, found sack po...|    1|               -0.75|\n",
      "|           politics|Feds take fall fi...|    2|0.024999999999999994|\n",
      "|          AskReddit|   to, omgomgomgomg |    0|                 0.0|\n",
      "|           gonewild|moved quite bit a...|    1| 0.11666666666666665|\n",
      "+-------------------+--------------------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def sentiment_fnc(text):\n",
    "    return TextBlob(text).sentiment.polarity #gives the polarity of the sentiment, [-1.0, 1.0]\n",
    "    \n",
    "\n",
    "sentiment_udf = udf(lambda x: sentiment_fnc(x)) \n",
    "spark_session.udf.register(\"sentiment_udf\", sentiment_udf)\n",
    "rcb_df = rcb_df.withColumn('sentiment_score',sentiment_udf('body').cast('double'))\n",
    "\n",
    "rcb_df.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b940d368-0a4b-4c3f-9d46-6a1aee212246",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e927c9b5-dfbb-46c2-bb31-8e51486ed441",
   "metadata": {},
   "source": [
    "### Most kindest/popular subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34ba4abc-dd99-4447-9f51-4087ea7761a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 20 kindest subreddits based on average comment score are:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:=======================================================> (30 + 1) / 31]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+\n",
      "|         subreddit|        avg(score)|\n",
      "+------------------+------------------+\n",
      "|          DateRape|             59.25|\n",
      "|            raerth| 52.63157894736842|\n",
      "|        bestof2009|41.943885653785074|\n",
      "| arboriculturalist|              27.0|\n",
      "|     announcements|10.680832759807295|\n",
      "|            USPE08|10.533333333333333|\n",
      "|            treees|              10.0|\n",
      "|    FFFUUUUUX_News|              10.0|\n",
      "|              blog| 8.358232181761593|\n",
      "|         YourMoney|               8.0|\n",
      "|          moonhoax|               8.0|\n",
      "|         introvert| 7.838709677419355|\n",
      "|theshittiestadvice|               7.5|\n",
      "|              rand|               7.0|\n",
      "|            getout|               7.0|\n",
      "|        notetoself|               6.8|\n",
      "|               ads| 6.716828478964401|\n",
      "|    doesanyoneelse|               6.6|\n",
      "|             gamin|               6.5|\n",
      "|             funny| 6.289259828684384|\n",
      "+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "avg_subreddit_score = data_frame.groupBy(\"subreddit\").agg({'score': 'avg'})\n",
    "avg_subreddit_score_sorted = avg_subreddit_score.orderBy('avg(score)',ascending = False)\n",
    "print(\"The top 20 kindest subreddits based on average comment score are:\")\n",
    "avg_subreddit_score_sorted.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c6b37e-189a-4ca8-9d34-cbfd9015d33e",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e25666d-7d7e-4c4c-a0ac-ffe090b35d30",
   "metadata": {},
   "source": [
    "### What are the most active subreddits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3463637-a105-4171-a3bf-115dd55c59ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subreddit_frequency = data_frame.groupby(\"subreddit\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "464d13cd-558b-4f3b-ae4c-8bac4f0ecb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:=====================================================>   (29 + 2) / 31]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+\n",
      "|          subreddit|  count|\n",
      "+-------------------+-------+\n",
      "|          AskReddit|1463220|\n",
      "|         reddit.com| 568859|\n",
      "|               pics| 533535|\n",
      "|               IAmA| 308264|\n",
      "|           politics| 302355|\n",
      "|             gaming| 287371|\n",
      "|                WTF| 254037|\n",
      "|              funny| 195779|\n",
      "|            atheism| 170821|\n",
      "|          worldnews| 132202|\n",
      "|            science| 127817|\n",
      "|        programming| 113933|\n",
      "|         technology|  95349|\n",
      "|              trees|  80618|\n",
      "|    DoesAnybodyElse|  71002|\n",
      "|fffffffuuuuuuuuuuuu|  63443|\n",
      "|              Music|  63013|\n",
      "|relationship_advice|  55970|\n",
      "|    TwoXChromosomes|  55107|\n",
      "|             videos|  50021|\n",
      "+-------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_subreddit_f = df_subreddit_frequency.sort('count',ascending=False).show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb45b7a9-1e5e-4b4c-a7ea-00d725e5a30a",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cb2df8-a557-4853-b3c1-3b390538f6dd",
   "metadata": {},
   "source": [
    "## Execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f47d47ba-909a-4f82-b9e3-9acee888e2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 195.1320242881775\n"
     ]
    }
   ],
   "source": [
    "print(f\"Execution time: {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f042798-0428-4cc8-8e91-371f70e8339a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_session.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d396a3-4253-457d-a909-9eae79f33382",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
